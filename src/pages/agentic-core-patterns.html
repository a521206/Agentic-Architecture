<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Agentic Core Patterns</title>
    <link rel="stylesheet" href="../css/main.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body class="pattern-page">
    <div class="content">
        <a href="agentic-design-pattern.html" class="back-button">
            <i class="fas fa-arrow-left"></i> Back to Main
        </a>
        
        <header>
            <h1>Agentic Core Patterns</h1>
            <p class="subtitle">Foundation patterns for agentic systems</p>
        </header>

        <nav class="nav-tiles">
            <a href="#prompt-chaining" class="nav-tile">
                <div class="pattern-icon">
                    <i class="fas fa-link"></i>
                </div>
                <h3>Prompt Chaining</h3>
                <p>Sequential task decomposition for complex workflows</p>
            </a>

            <a href="#routing" class="nav-tile">
                <div class="pattern-icon">
                    <i class="fas fa-route"></i>
                </div>
                <h3>Routing</h3>
                <p>Intelligent input direction to specialized sub-agents</p>
            </a>

            <a href="#parallelization" class="nav-tile">
                <div class="pattern-icon">
                    <i class="fas fa-code-branch"></i>
                </div>
                <h3>Parallelization</h3>
                <p>Concurrent task execution for improved efficiency</p>
            </a>

            <a href="#reflection" class="nav-tile">
                <div class="pattern-icon">
                    <i class="fas fa-brain"></i>
                </div>
                <h3>Reflection</h3>
                <p>Self-evaluation and continuous improvement</p>
            </a>

            <a href="#planning" class="nav-tile">
                <div class="pattern-icon">
                    <i class="fas fa-project-diagram"></i>
                </div>
                <h3>Planning</h3>
                <p>Goal-oriented task structuring and sequencing</p>
            </a>
        </nav>

        <section id="prompt-chaining" class="pattern-section">
            <div class="pattern-header">
                <h2><i class="fas fa-link"></i> Prompt Chaining</h2>
            </div>
            <div class="pattern-description">
                <h3><i class="fas fa-info-circle"></i> Description</h3>
                <p>Prompt Chaining is a pattern that breaks down complex tasks into a sequence of smaller, focused prompts. Each prompt in the chain builds upon the results of previous prompts, creating a structured flow of information and reasoning. This pattern is particularly useful for complex tasks that require multiple steps of processing or reasoning.</p>
                
                <p>There are several approaches to implementing prompt chaining:</p>
                <ul>
                    <li><strong>Sequential Chains:</strong> Linear sequence of prompts where each step depends on the previous one.</li>
                    <li><strong>Conditional Chains:</strong> Branches based on intermediate results or conditions.</li>
                    <li><strong>DSPy Modules:</strong> Stanford's DSPy provides a declarative way to compose complex chains with automatic optimization. <a href="https://github.com/stanfordnlp/dspy" target="_blank">Read about DSPy</a>.</li>
                    <li><strong>LangChain Sequential Chains:</strong> LangChain's implementation of sequential prompt chains with built-in memory and state management. <a href="https://python.langchain.com/docs/modules/chains/" target="_blank">Read about LangChain Chains</a>.</li>
                </ul>
            </div>
            <div class="pattern-implementation">
                <h3><i class="fas fa-code"></i> Implementation using DSPy</h3>
                <pre><code>import dspy
from dspy.teleprompt import BootstrapFewShot
from dspy.evaluate import Evaluate
from typing import List, Dict

# Define the signature for our chain
class ResearchChain(dspy.Signature):
    """Research a topic and generate a summary."""
    topic: str = dspy.InputField()
    research: str = dspy.OutputField(desc="Research findings")
    summary: str = dspy.OutputField(desc="Concise summary")

# Define the modules in our chain
class ResearchModule(dspy.Module):
    def __init__(self):
        super().__init__()
        self.research = dspy.ChainOfThought("topic -> research")
    
    def forward(self, topic: str) -> str:
        return self.research(topic=topic)

class SummaryModule(dspy.Module):
    def __init__(self):
        super().__init__()
        self.summarize = dspy.ChainOfThought("research -> summary")
    
    def forward(self, research: str) -> str:
        return self.summarize(research=research)

# Compose the chain
class ResearchPipeline(dspy.Module):
    def __init__(self):
        super().__init__()
        self.research = ResearchModule()
        self.summarize = SummaryModule()
    
    def forward(self, topic: str) -> Dict[str, str]:
        research = self.research(topic)
        summary = self.summarize(research)
        return {"research": research, "summary": summary}

# Example usage
if __name__ == "__main__":
    # Configure DSPy
    dspy.configure(lm=dspy.OpenAI())
    
    # Create and compile the pipeline
    pipeline = ResearchPipeline()
    
    # Example topics
    topics = [
        "The impact of AI on healthcare",
        "Sustainable energy solutions",
        "Future of remote work"
    ]
    
    # Process each topic
    for topic in topics:
        print(f"\nResearching: {topic}")
        result = pipeline(topic)
        print(f"Research: {result['research']}")
        print(f"Summary: {result['summary']}")</code></pre>
            </div>
            <div class="pattern-use-cases">
                <h3><i class="fas fa-lightbulb"></i> Use Cases</h3>
                <ul>
                    <li>
                        <strong>Research and Analysis</strong>
                        <p>Break down complex research tasks into sequential steps: data gathering, analysis, and synthesis. This enables systematic processing of information and generation of comprehensive reports.</p>
                        <a href="https://www.analyticsvidhya.com/blog/2023/12/research-chains/" target="_blank">Read about Research Chains</a>
                    </li>
                    <li>
                        <strong>Content Generation</strong>
                        <p>Create structured content generation pipelines for articles, reports, or documentation. This allows for consistent quality and style across different content types.</p>
                        <a href="https://www.datacamp.com/blog/content-generation-chains" target="_blank">Learn about Content Generation</a>
                    </li>
                    <li>
                        <strong>Code Generation</strong>
                        <p>Implement multi-step code generation with planning, implementation, and testing phases. This ensures high-quality, well-structured code output.</p>
                        <a href="https://blog.langchain.dev/code-generation-chains/" target="_blank">Explore Code Generation</a>
                    </li>
                    <li>
                        <strong>Data Processing</strong>
                        <p>Create pipelines for data cleaning, transformation, and analysis. This enables systematic processing of complex datasets.</p>
                        <a href="https://www.analyticsvidhya.com/blog/2023/12/data-processing-chains/" target="_blank">Read about Data Processing</a>
                    </li>
                    <li>
                        <strong>Decision Support</strong>
                        <p>Build decision-making systems that break down complex decisions into logical steps. This enables transparent and explainable decision processes.</p>
                        <a href="https://www.datacamp.com/blog/decision-support-chains" target="_blank">Learn about Decision Support</a>
                    </li>
                </ul>
            </div>
        </section>

        <section id="routing">
            <h2>Routing</h2>
            <div class="pattern-content">
                <div class="pattern-description">
                    <h3><i class="fas fa-info-circle"></i> Description</h3>
                    <p>Routing is a pattern that directs inputs to different specialized agents or chains based on their content or purpose. It's like a traffic controller for AI agents, ensuring each query reaches the most appropriate handler. This pattern is particularly useful when you have multiple specialized agents and need to determine which one should handle a particular request.</p>
                    
                    <p>There are several approaches to implementing routing:</p>
                    <ul>
                        <li><strong>Rule-based Routing:</strong> Uses predefined rules or conditions to direct inputs to specific handlers.</li>
                        <li><strong>LLM-based Classification:</strong> Uses a language model to analyze the input and determine the appropriate handler.</li>
                        <li><strong>LangChain Router Chains:</strong> LangChain provides specific router chains that use an LLM to classify an input and choose the next chain to execute. <a href="https://python.langchain.com/docs/modules/chains/router" target="_blank">Read about LangChain Routers</a>.</li>
                        <li><strong>OpenAI Function Calling:</strong> While primarily for tool use, the underlying mechanism of choosing which function to call based on a prompt is a form of routing. <a href="https://platform.openai.com/docs/guides/function-calling" target="_blank">Read about OpenAI Function Calling</a>.</li>
                    </ul>
                </div>
                
                <div class="pattern-characteristics">
                    <h3><i class="fas fa-puzzle-piece"></i> Key Components</h3>
                    <ul>
                        <li>Input Analyzer: Evaluates input content and context</li>
                        <li>Routing Rules: Defines routing logic and conditions</li>
                        <li>Handler Registry: Maps routes to specific handlers</li>
                        <li>Fallback Mechanism: Handles unmatched inputs</li>
                    </ul>
                </div>

                <div class="pattern-implementation">
                    <h3><i class="fas fa-code"></i> Implementation using LangGraph</h3>
                    <pre><code>from typing import Dict, List, Any, TypedDict, Annotated
from langchain_core.messages import BaseMessage, HumanMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.tools import tool

# Define tools for each agent
@tool
def check_order_status(order_id: str) -> str:
    """Check the status of an order."""
    return f"Order {order_id} is in transit"

@tool
def get_product_info(product: str) -> str:
    """Get information about a product."""
    return f"Product {product} is available in stock"

# Create specialized agents
def create_agent(name: str, system_prompt: str, tools: List = None):
    llm = ChatOpenAI(temperature=0)
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="messages"),
        MessagesPlaceholder(variable_name="agent_scratchpad")
    ])
    return create_openai_functions_agent(llm, tools or [], prompt)

# Create the supervisor agent
supervisor = create_agent(
    "supervisor",
    """You are a supervisor agent that routes queries to specialized agents.
    Choose the most appropriate agent based on the query content.
    Available agents: customer_support, order_status, product_info""",
    [check_order_status, get_product_info]
)

# Create specialized agents
agents = {
    "customer_support": create_agent(
        "customer_support",
        "You are a customer support agent. Help customers with their inquiries.",
        [check_order_status, get_product_info]
    ),
    "order_status": create_agent(
        "order_status",
        "You are an order status specialist. Help customers track their orders.",
        [check_order_status]
    ),
    "product_info": create_agent(
        "product_info",
        "You are a product specialist. Provide detailed product information.",
        [get_product_info]
    )
}

# Create the workflow
def create_workflow():
    # Define the state
    class AgentState(TypedDict):
        messages: List[BaseMessage]
        next: str
        agent_scratchpad: List[BaseMessage]

    # Create the graph
    workflow = StateGraph(AgentState)
    
    # Add nodes for each agent
    for name, agent in agents.items():
        workflow.add_node(name, AgentExecutor(agent=agent, tools=agent.tools))
    
    # Add supervisor node
    workflow.add_node("supervisor", AgentExecutor(agent=supervisor, tools=supervisor.tools))
    
    # Define the router
    def router(state: AgentState) -> str:
        if not state["messages"]:
            return END
        return state["next"] or "supervisor"
    
    # Add edges
    workflow.add_conditional_edges(
        "supervisor",
        router,
        {name: name for name in agents.keys()} | {END: END}
    )
    
    for name in agents.keys():
        workflow.add_edge(name, "supervisor")
    
    workflow.set_entry_point("supervisor")
    return workflow.compile()

# Example usage
if __name__ == "__main__":
    app = create_workflow()
    
    # Example queries
    queries = [
        "What's the status of order #12345?",
        "Tell me about the new iPhone features",
        "I need help with a return"
    ]
    
    for query in queries:
        print(f"\nProcessing: {query}")
        result = app.invoke({
            "messages": [HumanMessage(content=query)],
            "next": "",
            "agent_scratchpad": []
        })
        print(f"Response: {result['messages'][-1].content}")</code></pre>
                </div>

                <div class="pattern-use-cases">
                    <h3><i class="fas fa-lightbulb"></i> Use Cases</h3>
                    <ul>
                        <li>
                            <strong>Customer Service Automation</strong>
                            <p>Route customer inquiries to specialized agents based on query type (billing, technical support, product information). This ensures each query is handled by the most appropriate agent, improving response quality and efficiency.</p>
                            <a href="https://www.analyticsvidhya.com/blog/2023/12/agent-routing/" target="_blank">Read about Customer Service Routing</a>
                        </li>
                        <li>
                            <strong>Content Moderation</strong>
                            <p>Direct content to different moderation agents based on content type and risk level. This enables efficient content screening and appropriate handling of different types of content violations.</p>
                            <a href="https://www.datacamp.com/blog/ai-content-moderation" target="_blank">Learn about AI Content Moderation</a>
                        </li>
                        <li>
                            <strong>Multi-Agent Workflows</strong>
                            <p>Coordinate complex tasks across multiple specialized agents. This allows for sophisticated problem-solving by leveraging the strengths of different agents in a coordinated manner.</p>
                            <a href="https://blog.langchain.dev/langgraph-multi-agent-workflows/" target="_blank">Explore Multi-Agent Workflows</a>
                        </li>
                        <li>
                            <strong>Document Processing</strong>
                            <p>Route documents to appropriate processing agents based on document type and content. This enables efficient handling of different document formats and processing requirements.</p>
                            <a href="https://www.analyticsvidhya.com/blog/2023/12/document-processing-agents/" target="_blank">Read about Document Processing</a>
                        </li>
                        <li>
                            <strong>API Gateway</strong>
                            <p>Route API requests to appropriate microservices or handlers based on request type and parameters. This enables efficient request handling and load distribution across services.</p>
                            <a href="https://www.datacamp.com/blog/ai-api-gateway" target="_blank">Learn about AI API Gateway</a>
                        </li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="parallelization" class="pattern-section">
            <div class="pattern-header">
                <h2><i class="fas fa-code-branch"></i> Parallelization</h2>
            </div>
            <div class="pattern-description">
                <h3><i class="fas fa-info-circle"></i> Description</h3>
                <p>Parallelization is a pattern that enables concurrent execution of multiple tasks or agents, significantly improving performance and throughput. This pattern is particularly useful for tasks that can be executed independently or when dealing with multiple data sources or processing streams.</p>
                
                <p>There are several approaches to implementing parallelization:</p>
                <ul>
                    <li><strong>Async/Await:</strong> Python's asyncio for concurrent execution of I/O-bound tasks.</li>
                    <li><strong>Threading:</strong> For CPU-bound tasks that can benefit from parallel execution.</li>
                    <li><strong>Process Pooling:</strong> For true parallel execution across multiple CPU cores.</li>
                    <li><strong>Distributed Processing:</strong> For scaling across multiple machines or services.</li>
                </ul>
            </div>
            <div class="pattern-implementation">
                <h3><i class="fas fa-code"></i> Implementation using asyncio and ProcessPoolExecutor</h3>
                <pre><code>import asyncio
from typing import List, Dict, Any
from concurrent.futures import ProcessPoolExecutor
from dataclasses import dataclass
from openai import AsyncOpenAI
import time

@dataclass
class Task:
    """Represents a task to be processed."""
    id: str
    content: str
    priority: int = 1

class ParallelProcessor:
    def __init__(self, api_key: str, max_workers: int = 4):
        self.client = AsyncOpenAI(api_key=api_key)
        self.max_workers = max_workers
        self.process_pool = ProcessPoolExecutor(max_workers=max_workers)
    
    async def process_task(self, task: Task) -> Dict[str, Any]:
        """Process a single task asynchronously."""
        try:
            # Simulate different processing times based on priority
            await asyncio.sleep(1 / task.priority)
            
            # Process the task using OpenAI
            response = await self.client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[{"role": "user", "content": task.content}]
            )
            
            return {
                "task_id": task.id,
                "result": response.choices[0].message.content,
                "status": "completed"
            }
        except Exception as e:
            return {
                "task_id": task.id,
                "error": str(e),
                "status": "failed"
            }
    
    async def process_batch(self, tasks: List[Task]) -> List[Dict[str, Any]]:
        """Process multiple tasks concurrently."""
        # Create tasks for concurrent execution
        async_tasks = [self.process_task(task) for task in tasks]
        
        # Execute tasks concurrently and gather results
        results = await asyncio.gather(*async_tasks)
        return results
    
    def process_cpu_bound(self, data: List[Any]) -> List[Any]:
        """Process CPU-bound tasks using process pool."""
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            results = list(executor.map(self._cpu_bound_task, data))
        return results
    
    def _cpu_bound_task(self, data: Any) -> Any:
        """Example CPU-bound task."""
        # Simulate CPU-intensive processing
        time.sleep(0.1)
        return data * 2

async def main():
    # Initialize processor
    processor = ParallelProcessor(api_key="your-api-key")
    
    # Example tasks
    tasks = [
        Task("1", "Analyze this text: AI is transforming industries", 2),
        Task("2", "Summarize: Machine learning applications", 1),
        Task("3", "Generate ideas for: Future of work", 3),
        Task("4", "Evaluate: Impact of automation", 2)
    ]
    
    # Process tasks concurrently
    print("Processing tasks concurrently...")
    start_time = time.time()
    results = await processor.process_batch(tasks)
    end_time = time.time()
    
    print(f"\nProcessed {len(results)} tasks in {end_time - start_time:.2f} seconds")
    for result in results:
        print(f"\nTask {result['task_id']}:")
        print(f"Status: {result['status']}")
        if result['status'] == 'completed':
            print(f"Result: {result['result']}")
        else:
            print(f"Error: {result['error']}")
    
    # Example of CPU-bound processing
    print("\nProcessing CPU-bound tasks...")
    data = list(range(10))
    results = processor.process_cpu_bound(data)
    print(f"Results: {results}")

if __name__ == "__main__":
    asyncio.run(main())</code></pre>
            </div>
            <div class="pattern-use-cases">
                <h3><i class="fas fa-lightbulb"></i> Use Cases</h3>
                <ul>
                    <li>
                        <strong>Data Processing Pipelines</strong>
                        <p>Process large datasets concurrently by splitting them into chunks and processing them in parallel. This significantly reduces processing time for large-scale data operations.</p>
                        <a href="https://www.analyticsvidhya.com/blog/2023/12/parallel-data-processing/" target="_blank">Read about Parallel Data Processing</a>
                    </li>
                    <li>
                        <strong>API Integration</strong>
                        <p>Make multiple API calls concurrently to different services. This improves response times when integrating with multiple external systems.</p>
                        <a href="https://www.datacamp.com/blog/async-api-integration" target="_blank">Learn about Async API Integration</a>
                    </li>
                    <li>
                        <strong>Content Generation</strong>
                        <p>Generate multiple content pieces simultaneously. This enables efficient creation of large content sets while maintaining quality.</p>
                        <a href="https://blog.langchain.dev/parallel-content-generation/" target="_blank">Explore Parallel Content Generation</a>
                    </li>
                    <li>
                        <strong>Model Training</strong>
                        <p>Train multiple models or hyperparameter combinations in parallel. This accelerates the model development and optimization process.</p>
                        <a href="https://www.analyticsvidhya.com/blog/2023/12/parallel-model-training/" target="_blank">Read about Parallel Model Training</a>
                    </li>
                    <li>
                        <strong>Real-time Analytics</strong>
                        <p>Process multiple data streams concurrently for real-time analysis. This enables immediate insights from multiple data sources.</p>
                        <a href="https://www.datacamp.com/blog/real-time-analytics" target="_blank">Learn about Real-time Analytics</a>
                    </li>
                </ul>
            </div>
        </section>

        <section id="reflection" class="pattern-section">
            <div class="pattern-header">
                <h2><i class="fas fa-brain"></i> Reflection</h2>
            </div>
            <div class="pattern-description">
                <h3><i class="fas fa-info-circle"></i> Description</h3>
                <p>Reflection is a pattern that enables AI agents to evaluate their own performance, learn from past experiences, and improve their future actions. This pattern is crucial for building self-improving systems that can adapt to new situations and optimize their behavior over time.</p>
                
                <p>There are several approaches to implementing reflection:</p>
                <ul>
                    <li><strong>Self-Evaluation:</strong> Agents analyze their own outputs and decisions for quality and correctness.</li>
                    <li><strong>Feedback Integration:</strong> Incorporate external feedback to improve future responses.</li>
                    <li><strong>Memory-Based Learning:</strong> Store and learn from past interactions and outcomes.</li>
                    <li><strong>Meta-Cognitive Analysis:</strong> Evaluate the reasoning process and decision-making strategies.</li>
                </ul>
            </div>
            <div class="pattern-implementation">
                <h3><i class="fas fa-code"></i> Implementation using OpenAI API</h3>
                <pre><code>from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
from openai import OpenAI
import json

@dataclass
class Reflection:
    """Represents a reflection on a task or interaction."""
    task_id: str
    original_output: str
    evaluation: Dict[str, Any]
    improvements: List[str]
    timestamp: datetime = datetime.now()

class ReflectiveAgent:
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)
        self.memory: List[Reflection] = []
    
    def _evaluate_output(self, task: str, output: str) -> Dict[str, Any]:
        """Evaluate the quality and correctness of an output."""
        prompt = f"""Evaluate the following output for the task: {task}

Output: {output}

Provide a detailed evaluation in JSON format with the following structure:
{{
    "accuracy": float,  # 0-1 score
    "completeness": float,  # 0-1 score
    "relevance": float,  # 0-1 score
    "strengths": [string],
    "weaknesses": [string]
}}"""

        response = self.client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        
        return json.loads(response.choices[0].message.content)
    
    def _generate_improvements(self, task: str, output: str, evaluation: Dict[str, Any]) -> List[str]:
        """Generate specific improvements based on evaluation."""
        prompt = f"""Based on the following evaluation, suggest specific improvements for the output:

Task: {task}
Output: {output}
Evaluation: {json.dumps(evaluation, indent=2)}

Provide a list of concrete improvements in JSON format:
{{
    "improvements": [string]
}}"""

        response = self.client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        
        return json.loads(response.choices[0].message.content)["improvements"]
    
    def _apply_improvements(self, task: str, output: str, improvements: List[str]) -> str:
        """Apply the suggested improvements to the output."""
        prompt = f"""Improve the following output based on these suggestions:

Task: {task}
Original Output: {output}
Improvements: {json.dumps(improvements, indent=2)}

Provide an improved version of the output that addresses all the suggestions."""

        response = self.client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}]
        )
        
        return response.choices[0].message.content
    
    def process_with_reflection(self, task: str, initial_output: str) -> Dict[str, Any]:
        """Process a task with reflection and improvement."""
        # Evaluate the output
        evaluation = self._evaluate_output(task, initial_output)
        
        # Generate improvements
        improvements = self._generate_improvements(task, initial_output, evaluation)
        
        # Apply improvements
        improved_output = self._apply_improvements(task, initial_output, improvements)
        
        # Store reflection
        reflection = Reflection(
            task_id=task,
            original_output=initial_output,
            evaluation=evaluation,
            improvements=improvements
        )
        self.memory.append(reflection)
        
        return {
            "original_output": initial_output,
            "evaluation": evaluation,
            "improvements": improvements,
            "improved_output": improved_output
        }
    
    def get_learning_insights(self) -> Dict[str, Any]:
        """Analyze past reflections to generate learning insights."""
        if not self.memory:
            return {"message": "No reflections available for analysis"}
        
        # Prepare reflection history
        history = "\n".join([
            f"Task: {r.task_id}\n"
            f"Evaluation: {json.dumps(r.evaluation, indent=2)}\n"
            f"Improvements: {json.dumps(r.improvements, indent=2)}\n"
            for r in self.memory[-5:]  # Analyze last 5 reflections
        ])
        
        prompt = f"""Analyze the following reflection history and provide insights:

{history}

Provide insights in JSON format:
{{
    "common_improvements": [string],
    "performance_trends": [string],
    "recommendations": [string]
}}"""

        response = self.client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        
        return json.loads(response.choices[0].message.content)

# Example usage
if __name__ == "__main__":
    agent = ReflectiveAgent(api_key="your-api-key")
    
    # Example task
    task = "Explain the concept of machine learning to a beginner"
    initial_output = """Machine learning is when computers learn from data. They can make predictions and decisions without being explicitly programmed."""
    
    # Process with reflection
    result = agent.process_with_reflection(task, initial_output)
    
    print("Original Output:", result["original_output"])
    print("\nEvaluation:", json.dumps(result["evaluation"], indent=2))
    print("\nImprovements:", json.dumps(result["improvements"], indent=2))
    print("\nImproved Output:", result["improved_output"])
    
    # Get learning insights
    insights = agent.get_learning_insights()
    print("\nLearning Insights:", json.dumps(insights, indent=2))</code></pre>
            </div>
            <div class="pattern-use-cases">
                <h3><i class="fas fa-lightbulb"></i> Use Cases</h3>
                <ul>
                    <li>
                        <strong>Content Quality Assurance</strong>
                        <p>Automatically evaluate and improve content quality through self-reflection. This ensures consistent high-quality output across all generated content.</p>
                        <a href="https://www.analyticsvidhya.com/blog/2023/12/ai-content-quality/" target="_blank">Read about Content Quality</a>
                    </li>
                    <li>
                        <strong>Code Review and Improvement</strong>
                        <p>Enable AI to review and improve its own code generation. This leads to more robust and maintainable code output.</p>
                        <a href="https://www.datacamp.com/blog/ai-code-review" target="_blank">Learn about AI Code Review</a>
                    </li>
                    <li>
                        <strong>Learning Systems</strong>
                        <p>Build systems that learn from their mistakes and improve over time. This enables continuous improvement in performance and accuracy.</p>
                        <a href="https://blog.langchain.dev/learning-systems/" target="_blank">Explore Learning Systems</a>
                    </li>
                    <li>
                        <strong>Quality Control</strong>
                        <p>Implement automated quality control through self-evaluation. This ensures consistent quality across all outputs.</p>
                        <a href="https://www.analyticsvidhya.com/blog/2023/12/ai-quality-control/" target="_blank">Read about Quality Control</a>
                    </li>
                    <li>
                        <strong>Performance Optimization</strong>
                        <p>Continuously optimize system performance through reflection and improvement. This leads to better efficiency and effectiveness.</p>
                        <a href="https://www.datacamp.com/blog/ai-performance" target="_blank">Learn about Performance Optimization</a>
                    </li>
                </ul>
            </div>
        </section>

        <section id="planning" class="pattern-section">
            <div class="pattern-header">
                <h2><i class="fas fa-route"></i> Planning</h2>
            </div>
            <div class="pattern-description">
                <h3><i class="fas fa-info-circle"></i> Description</h3>
                <p>Planning is a pattern that enables AI agents to create and execute sequences of actions to achieve specific goals. By breaking down complex tasks into manageable steps and considering dependencies and constraints, this pattern enables systematic problem-solving and goal achievement.</p>
                
                <p>There are several approaches to implementing planning systems:</p>
                <ul>
                    <li><strong>Hierarchical Planning:</strong> Breaking down goals into sub-goals and creating hierarchical action plans.</li>
                    <li><strong>Reactive Planning:</strong> Adapting plans based on real-time feedback and changing conditions.</li>
                    <li><strong>Constraint-Based Planning:</strong> Considering various constraints and dependencies while creating plans.</li>
                    <li><strong>Goal-Oriented Planning:</strong> Focusing on achieving specific goals through systematic action sequences.</li>
                </ul>
            </div>
            <div class="pattern-implementation">
                <h3><i class="fas fa-code"></i> Implementation using OpenAI API and NetworkX</h3>
                <pre><code>from typing import List, Dict, Any, Optional, Set
from dataclasses import dataclass
from openai import OpenAI
import json
from datetime import datetime
import networkx as nx

@dataclass
class Action:
    """Represents a single action in a plan."""
    name: str
    description: str
    prerequisites: Set[str]
    effects: Set[str]
    duration: int  # in minutes
    resources: Dict[str, Any]

@dataclass
class Goal:
    """Represents a goal to be achieved."""
    name: str
    description: str
    conditions: Set[str]
    priority: int

class Planner:
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)
        self.actions: Dict[str, Action] = {}
        self.goals: List[Goal] = []
        self.plan_graph = nx.DiGraph()
    
    def add_action(self, action: Action):
        """Add an action to the planner's knowledge base."""
        self.actions[action.name] = action
        self.plan_graph.add_node(action.name, **action.__dict__)
    
    def add_goal(self, goal: Goal):
        """Add a goal to be achieved."""
        self.goals.append(goal)
    
    def _create_action_graph(self) -> nx.DiGraph:
        """Create a graph of actions and their dependencies."""
        graph = nx.DiGraph()
        
        # Add all actions as nodes
        for action in self.actions.values():
            graph.add_node(action.name, **action.__dict__)
        
        # Add edges based on prerequisites and effects
        for action in self.actions.values():
            for prereq in action.prerequisites:
                # Find actions that produce this prerequisite
                for other_action in self.actions.values():
                    if prereq in other_action.effects:
                        graph.add_edge(other_action.name, action.name)
        
        return graph
    
    async def generate_plan(self, initial_state: Set[str]) -> Dict[str, Any]:
        """Generate a plan to achieve the goals from the initial state."""
        # Create action graph
        action_graph = self._create_action_graph()
        
        # Sort goals by priority
        sorted_goals = sorted(self.goals, key=lambda g: g.priority, reverse=True)
        
        # Generate plan for each goal
        plan = []
        current_state = initial_state.copy()
        
        for goal in sorted_goals:
            # Find actions needed to achieve goal
            needed_conditions = goal.conditions - current_state
            if not needed_conditions:
                continue
            
            # Use LLM to select actions
            prompt = f"""Given the following:
Current state: {current_state}
Needed conditions: {needed_conditions}
Available actions: {json.dumps([a.__dict__ for a in self.actions.values()], indent=2)}

Select the best sequence of actions to achieve the needed conditions.
Consider dependencies, resources, and efficiency."""

            response = await self.client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[{"role": "user", "content": prompt}]
            )
            
            # Parse selected actions
            selected_actions = json.loads(response.choices[0].message.content)
            
            # Add actions to plan
            for action_name in selected_actions:
                action = self.actions[action_name]
                plan.append({
                    "action": action_name,
                    "description": action.description,
                    "duration": action.duration,
                    "resources": action.resources
                })
                current_state.update(action.effects)
        
        return {
            "goals": [g.__dict__ for g in sorted_goals],
            "plan": plan,
            "final_state": current_state
        }
    
    async def execute_plan(self, plan: Dict[str, Any]) -> Dict[str, Any]:
        """Execute a generated plan and track progress."""
        execution_log = []
        current_state = set()
        
        for step in plan["plan"]:
            action = self.actions[step["action"]]
            
            # Check prerequisites
            if not action.prerequisites.issubset(current_state):
                execution_log.append({
                    "step": step["action"],
                    "status": "failed",
                    "reason": "Prerequisites not met",
                    "missing": list(action.prerequisites - current_state)
                })
                continue
            
            # Execute action
            execution_log.append({
                "step": step["action"],
                "status": "executed",
                "start_time": datetime.now().isoformat(),
                "duration": step["duration"],
                "resources_used": step["resources"]
            })
            
            # Update state
            current_state.update(action.effects)
        
        return {
            "execution_log": execution_log,
            "final_state": current_state,
            "success": all(log["status"] == "executed" for log in execution_log)
        }

# Example usage
async def main():
    # Initialize planner
    planner = Planner(api_key="your-api-key")
    
    # Define actions
    planner.add_action(Action(
        name="research_market",
        description="Research market conditions and opportunities",
        prerequisites=set(),
        effects={"market_knowledge"},
        duration=120,
        resources={"researcher": 1}
    ))
    
    planner.add_action(Action(
        name="develop_strategy",
        description="Develop business strategy based on market research",
        prerequisites={"market_knowledge"},
        effects={"business_strategy"},
        duration=180,
        resources={"strategist": 1}
    ))
    
    planner.add_action(Action(
        name="create_implementation_plan",
        description="Create detailed implementation plan",
        prerequisites={"business_strategy"},
        effects={"implementation_plan"},
        duration=90,
        resources={"planner": 1}
    ))
    
    # Define goals
    planner.add_goal(Goal(
        name="market_entry",
        description="Successfully enter a new market",
        conditions={"market_knowledge", "business_strategy", "implementation_plan"},
        priority=1
    ))
    
    # Generate and execute plan
    initial_state = set()
    plan = await planner.generate_plan(initial_state)
    print("\nGenerated Plan:")
    print(json.dumps(plan, indent=2))
    
    execution_result = await planner.execute_plan(plan)
    print("\nExecution Result:")
    print(json.dumps(execution_result, indent=2))

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())</code></pre>
            </div>
            <div class="pattern-use-cases">
                <h3><i class="fas fa-lightbulb"></i> Use Cases</h3>
                <ul>
                    <li>
                        <strong>Project Management</strong>
                        <p>Create and execute project plans with dependencies and resource allocation. This enables efficient project execution and management.</p>
                        <a href="https://www.analyticsvidhya.com/blog/2023/12/ai-project-planning/" target="_blank">Read about AI Project Planning</a>
                    </li>
                    <li>
                        <strong>Resource Optimization</strong>
                        <p>Plan and optimize resource allocation for various tasks. This leads to better resource utilization and cost efficiency.</p>
                        <a href="https://www.datacamp.com/blog/ai-resource-optimization" target="_blank">Learn about Resource Optimization</a>
                    </li>
                    <li>
                        <strong>Process Automation</strong>
                        <p>Automate complex processes by planning and executing sequences of actions. This enables efficient process automation.</p>
                        <a href="https://blog.langchain.dev/ai-process-automation/" target="_blank">Explore Process Automation</a>
                    </li>
                    <li>
                        <strong>Strategic Planning</strong>
                        <p>Develop and execute strategic plans for business operations. This enables systematic achievement of business goals.</p>
                        <a href="https://www.analyticsvidhya.com/blog/2023/12/ai-strategic-planning/" target="_blank">Read about Strategic Planning</a>
                    </li>
                    <li>
                        <strong>Workflow Management</strong>
                        <p>Plan and manage complex workflows with multiple dependencies. This enables efficient workflow execution and management.</p>
                        <a href="https://www.datacamp.com/blog/ai-workflow-management" target="_blank">Learn about Workflow Management</a>
                    </li>
                </ul>
            </div>
        </section>
    </div>
    <script src="../js/app.js"></script>
</body>
</html> 
